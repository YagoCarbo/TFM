{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\usuario\\anaconda3\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tiktoken) (2023.3.23)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tiktoken) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Requirement already satisfied: chromadb in c:\\users\\usuario\\anaconda3\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (1.5.0)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (2.29.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (1.9.2)\n",
      "Requirement already satisfied: hnswlib>=0.7 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (0.7.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (0.5.22)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (2.2.2)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (0.7.1)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (0.95.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (1.22.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from chromadb) (3.0.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.7)\n",
      "Requirement already satisfied: pytz in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2021.3)\n",
      "Requirement already satisfied: zstandard in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
      "Requirement already satisfied: lz4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from fastapi>=0.85.1->chromadb) (0.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.28->chromadb) (3.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (4.24.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (0.14.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (1.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (1.8.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (3.7)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (0.1.97)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (0.11.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.0.3)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.13.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.4.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (21.3)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (3.6.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2023.3.23)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (8.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.0.4)\n",
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken\n",
    "!pip install chromadb\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "import sys\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "import glob\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "import chromadb\n",
    "\n",
    "\n",
    "%env OPENAI_API_KEY=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_index = None\n",
    "persist_directory = r\"C:\\Users\\Usuario\\Desktop\\universidad\\TFM\\Economia\"\n",
    "pdf_folder=r\"C:\\Users\\Usuario\\Desktop\\universidad\\TFM\\Economia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdfs(folder_path):\n",
    "    global document_index \n",
    "    if document_index is None:\n",
    "        # Initialize OpenAI embeddings\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        # Initialize text splitter\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"puntos.\",\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=10,\n",
    "            length_function=len)\n",
    "        # Initialize list to hold processed documents\n",
    "        processed_docs = []\n",
    "        # Loop through all PDF files in folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.pdf'):\n",
    "                # Load PDF file\n",
    "                with open(os.path.join(folder_path, filename), 'rb') as f:\n",
    "                    pdf = PdfReader(f)\n",
    "                    # Loop through all pages in PDF\n",
    "                    for page_num in range(len(pdf.pages)):\n",
    "                        # Extract text from page\n",
    "                        page = pdf.pages[page_num]\n",
    "                        text = page.extract_text()\n",
    "                        # Split text into chunks\n",
    "                        chunks = text_splitter.split_text(text)\n",
    "                        # Add page number as metadata to each chunk\n",
    "                        for i, chunk in enumerate(chunks):\n",
    "                            metadata = {'page_num': page_num}\n",
    "                            processed_docs.append(TextLoader(chunk).load(metadata=metadata))\n",
    "\n",
    "        # Create Chroma vector database from processed documents\n",
    "        print('\\nLoading to Chroma')\n",
    "        vectordb = Chroma.from_documents(documents=processed_docs, embedding=embeddings, persist_directory=persist_directory)\n",
    "        print('\\nPersisting')\n",
    "        vectordb.persist()\n",
    "        print('\\nPersisted')\n",
    "        document_index = VectorStoreIndexWrapper(vectorstore=vectordb)\n",
    "    return document_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load() got an unexpected keyword argument 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19088/4103485015.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocess_pdfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpdf_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19088/3853638856.py\u001b[0m in \u001b[0;36mprocess_pdfs\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m     28\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                             \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'page_num'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpage_num\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                             \u001b[0mprocessed_docs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTextLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# Create Chroma vector database from processed documents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: load() got an unexpected keyword argument 'metadata'"
     ]
    }
   ],
   "source": [
    "process_pdfs(folder_path=pdf_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_document_index():\n",
    "    global document_index \n",
    "    if document_index is None:\n",
    "        print('\\nInitializing Document Index')\n",
    "        files = glob.glob(pdf_folder+'/*.pdf', recursive=False)\n",
    "        documents = [PyPDFLoader(f).load() for f in files]\n",
    "        documents = [item for sublist in documents for item in sublist]\n",
    "        embedding = OpenAIEmbeddings() # type: ignore\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"puntos.\",\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=10,\n",
    "            length_function=len) # A mirar entre pregunta\n",
    "        docs = text_splitter.split_documents(documents) # type: ignore\n",
    "        print('\\nLoading to Chroma')\n",
    "        vectordb = Chroma.from_documents(documents=docs, embedding=embedding, persist_directory=persist_directory)\n",
    "        print('\\nPersisting')\n",
    "        vectordb.persist()\n",
    "        print('\\nPersisted')\n",
    "        document_index = VectorStoreIndexWrapper(vectorstore=vectordb)\n",
    "    return document_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_index():\n",
    "    global document_index\n",
    "    if document_index is None:\n",
    "        print()\n",
    "        embedding = OpenAIEmbeddings() # type: ignore\n",
    "        vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "        document_index = VectorStoreIndexWrapper(vectorstore=vectordb)\n",
    "    return document_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_vectordb():\n",
    "    embedding = OpenAIEmbeddings() # type: ignore\n",
    "    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Document Index\n",
      "\n",
      "Loading to Chroma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: C:\\Users\\Usuario\\Desktop\\universidad\\TFM\\Economia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Persisting\n",
      "\n",
      "Persisted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreIndexWrapper(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x0000022F28E63400>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_document_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=get_document_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: C:\\Users\\Usuario\\Desktop\\universidad\\TFM\\Economia\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    gpt4, chain_type=\"stuff\", retriever=get_document_vectordb().as_retriever(),verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_2788/1084323516.py\", line 26, in getInput\n",
      "    res = chain({\"question\": params[0]})\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py\", line 142, in __call__\n",
      "    raise e\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py\", line 136, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\chains\\qa_with_sources\\base.py\", line 127, in _call\n",
      "    docs = self._get_docs(inputs)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\chains\\qa_with_sources\\retrieval.py\", line 45, in _get_docs\n",
      "    docs = self.retriever.get_relevant_documents(question)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\vectorstores\\base.py\", line 333, in get_relevant_documents\n",
      "    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\vectorstores\\chroma.py\", line 171, in similarity_search\n",
      "    docs_and_scores = self.similarity_search_with_score(query, k, filter=filter)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\vectorstores\\chroma.py\", line 216, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\embeddings\\openai.py\", line 245, in embed_query\n",
      "    embedding = self._embedding_func(text, engine=self.deployment)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\embeddings\\openai.py\", line 215, in _embedding_func\n",
      "    return embed_with_retry(self, input=[text], engine=engine)[\"data\"][0][\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\embeddings\\openai.py\", line 63, in embed_with_retry\n",
      "    return _embed_with_retry(**kwargs)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tenacity\\__init__.py\", line 406, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tenacity\\__init__.py\", line 351, in iter\n",
      "    return fut.result()\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 438, in result\n",
      "    return self.__get_result()\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tenacity\\__init__.py\", line 409, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\langchain\\embeddings\\openai.py\", line 61, in _embed_with_retry\n",
      "    return embeddings.client.create(**kwargs)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\openai\\api_resources\\embedding.py\", line 33, in create\n",
      "    response = super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: [''] is not valid under any of the given schemas - 'input'\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "root.title(\"ChatTFM\")\n",
    "root.iconbitmap('C:/Users/Usuario/Desktop/universidad/TFM/CUNEF.ico')\n",
    "p1 = PhotoImage(file = 'C:/Users/Usuario/Desktop/universidad/TFM/CUNEF.png')\n",
    "root.iconphoto(False, p1)\n",
    "root.geometry(\"1920x1080\")\n",
    "label1=Label(root,text=\"Hola! ¿Cómo puedo ayudarte?\")\n",
    "label1.pack()\n",
    "\n",
    "\n",
    "my_text = Entry(root, width=170)\n",
    "my_text.pack()\n",
    "\n",
    "\n",
    "\n",
    "def getInput():\n",
    "    a = my_text.get()\n",
    "    global params\n",
    "    params = [a]\n",
    "    my_text.delete(0, END)\n",
    "    my_label.config(text=\"Petición realizada: \"+ a)\n",
    "    ##Codigo sevilla\n",
    "    res = chain({\"question\": params[0]})\n",
    "    resultado= res['answer']\n",
    "    resultado_split = [resultado[i:i+150] for i in range(0, len(resultado), 150)]\n",
    "    resultado_formatted = \"\\n\".join(resultado_split)\n",
    "    my_label_respuesta.config(text=\"Respuesta: \"+resultado_formatted)\n",
    "\n",
    "\n",
    "\n",
    "Button(root, text = \"submit\",\n",
    "           command = getInput).pack()\n",
    "my_label =Label(root, text='')\n",
    "my_label.pack()\n",
    "\n",
    "\n",
    "my_label_respuesta =Label(root, text='')\n",
    "my_label_respuesta.pack()\n",
    "\n",
    "\n",
    "mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.12.0-py2.py3-none-any.whl (9.1 MB)\n",
      "     ---------------------------------------- 9.1/9.1 MB 7.5 MB/s eta 0:00:00\n",
      "Collecting altair>=3.2.0 (from streamlit)\n",
      "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "     -------------------------------------- 813.6/813.6 kB 5.1 MB/s eta 0:00:00\n",
      "Collecting blinker>=1.0.0 (from streamlit)\n",
      "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (8.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (4.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (1.22.4)\n",
      "Requirement already satisfied: packaging>=14.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (1.5.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (8.4.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=4.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (10.0.0)\n",
      "Collecting pydeck>=0.1.dev5 (from streamlit)\n",
      "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "     ---------------------------------------- 4.8/4.8 MB 4.9 MB/s eta 0:00:00\n",
      "Collecting pympler>=0.9 (from streamlit)\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "     -------------------------------------- 164.8/164.8 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (2.29.0)\n",
      "Collecting rich>=10.11.0 (from streamlit)\n",
      "  Downloading rich-13.3.5-py3-none-any.whl (238 kB)\n",
      "     ------------------------------------- 238.7/238.7 kB 14.3 MB/s eta 0:00:00\n",
      "Collecting semver (from streamlit)\n",
      "  Downloading semver-3.0.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: toml in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (4.4.0)\n",
      "Collecting tzlocal>=1.1 (from streamlit)\n",
      "  Downloading tzlocal-4.3-py3-none-any.whl (20 kB)\n",
      "Collecting validators>=0.2 (from streamlit)\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gitpython!=3.1.19 (from streamlit)\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "     ---------------------------------------- 184.3/184.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: watchdog in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from streamlit) (2.1.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from click>=7.0->streamlit) (0.4.4)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19->streamlit)\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->streamlit) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from packaging>=14.1->streamlit) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from python-dateutil->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2022.12.7)\n",
      "Collecting markdown-it-py<3.0.0,>=2.2.0 (from rich>=10.11.0->streamlit)\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "     ---------------------------------------- 84.5/84.5 kB ? eta 0:00:00\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->streamlit)\n",
      "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 9.1 MB/s eta 0:00:00\n",
      "Collecting pytz-deprecation-shim (from tzlocal>=1.1->streamlit)\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tzdata (from tzlocal>=1.1->streamlit)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ------------------------------------- 341.8/341.8 kB 20.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from validators>=0.2->streamlit) (5.1.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit)\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (58.0.4)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: validators\n",
      "  Building wheel for validators (setup.py): started\n",
      "  Building wheel for validators (setup.py): finished with status 'done'\n",
      "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19583 sha256=3e3ee6d775db0cc0e308356e159f9a9f200871c6e04f6e4a30cf86c1b081e6b7\n",
      "  Stored in directory: c:\\users\\usuario\\appdata\\local\\pip\\cache\\wheels\\2d\\f0\\a8\\1094fca7a7e5d0d12ff56e0c64675d72aa5cc81a5fc200e849\n",
      "Successfully built validators\n",
      "Installing collected packages: validators, tzdata, smmap, semver, pympler, pygments, mdurl, blinker, pytz-deprecation-shim, pydeck, markdown-it-py, gitdb, tzlocal, rich, gitpython, altair, streamlit\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.10.0\n",
      "    Uninstalling Pygments-2.10.0:\n",
      "      Successfully uninstalled Pygments-2.10.0\n",
      "Successfully installed altair-4.2.2 blinker-1.6.2 gitdb-4.0.10 gitpython-3.1.31 markdown-it-py-2.2.0 mdurl-0.1.2 pydeck-0.8.1b0 pygments-2.15.1 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 rich-13.3.5 semver-3.0.0 smmap-5.0.0 streamlit-1.12.0 tzdata-2023.3 tzlocal-4.3 validators-0.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Pandas requires version '3.0.0' or newer of 'jinja2' (version '2.11.3' currently installed).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2788/545655576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmymodel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"my first app\"\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\streamlit\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msource_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_source_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_string_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeltaGenerator\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_DeltaGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m from streamlit.runtime.scriptrunner import (\n\u001b[0;32m     72\u001b[0m     \u001b[0madd_script_run_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_add_script_run_ctx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\streamlit\\delta_generator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# DataFrame elements come in two flavors: \"Legacy\" and \"Arrow\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;31m# We select between them with the DataFrameElementSelectorMixin.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melements\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mArrowMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melements\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrow_altair\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mArrowAltairMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melements\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrow_vega_lite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mArrowVegaLiteMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\streamlit\\elements\\arrow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStyler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\style.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_to_buffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mjinja2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"jinja2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"DataFrame.style requires jinja2.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m from pandas.io.formats.style_render import (\n",
      "\u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Pandas requires version '3.0.0' or newer of 'jinja2' (version '2.11.3' currently installed)."
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import mymodel as m\n",
    "st.write(\"\"\"my first app\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
